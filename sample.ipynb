{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcAmAR943xTaRZJ57IGHUk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SruthiSuresh12/diabetic-retinopathy/blob/main/sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "wcQo_T8N90vG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = \"./diabetic-retinopathy-detection\"\n",
        "sample_zip = os.path.join(data_directory, \"sample.zip\")\n",
        "labels_csv = os.path.join(data_directory, \"trainLabels.csv\")\n",
        "# Extract sample.zip if not already extracted\n",
        "if os.path.exists(sample_zip):\n",
        "    print(\"Extracting sample.zip...\")\n",
        "    with zipfile.ZipFile(sample_zip, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(data_directory)\n",
        "    print(\"✅ Sample data extracted\")\n",
        "\n",
        "sample_dir = os.path.join(data_directory, \"sample\")\n",
        "\n",
        "# 2. Load labels and keep only sample images\n",
        "train_labels_df = pd.read_csv(labels_csv)\n",
        "\n",
        "# Add full image paths\n",
        "train_labels_df[\"image_path\"] = train_labels_df[\"image\"].apply(\n",
        "    lambda x: os.path.join(sample_dir, f\"{x}.jpeg\")\n",
        ")\n",
        "\n",
        "# Keep only rows where the image exists in sample/\n",
        "train_labels_df = train_labels_df[train_labels_df[\"image_path\"].apply(os.path.exists)].reset_index(drop=True)\n",
        "\n",
        "print(f\"✅ Found {len(train_labels_df)} labeled sample images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGwMDDGc93TQ",
        "outputId": "1a6a6eb9-7894-4ab7-dfb4-8838da55ea98"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting sample.zip...\n",
            "✅ Sample data extracted\n",
            "✅ Found 10 labeled sample images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, label):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.cast(img, tf.float32)\n",
        "\n",
        "    # Extract green channel\n",
        "    img_green = img[:, :, 1]\n",
        "\n",
        "    # CLAHE using numpy_function\n",
        "    img_clahe = tf.numpy_function(\n",
        "        func=lambda x: cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(x.astype(np.uint8)),\n",
        "        inp=[img_green],\n",
        "        Tout=tf.uint8\n",
        "    )\n",
        "    img_clahe.set_shape(img_green.shape)\n",
        "    img_processed = tf.image.grayscale_to_rgb(tf.expand_dims(img_clahe, axis=-1))\n",
        "\n",
        "    # Circle crop (wrap numpy in numpy_function)\n",
        "    def circle_crop(x):\n",
        "        h, w, _ = x.shape\n",
        "        center_x, center_y = w // 2, h // 2\n",
        "        radius = min(center_x, center_y)\n",
        "        Y, X = np.ogrid[:h, :w]\n",
        "        mask = (X - center_x) ** 2 + (Y - center_y) ** 2 <= radius ** 2\n",
        "        cropped = np.where(mask[..., None], x, 0)\n",
        "        return cropped.astype(np.uint8)\n",
        "\n",
        "    img_cropped = tf.numpy_function(circle_crop, [img_processed], tf.uint8)\n",
        "    img_cropped.set_shape(img_processed.shape)\n",
        "\n",
        "    # Resize & normalize\n",
        "    img_resized = tf.image.resize(img_cropped, (224, 224))\n",
        "    img_normalized = img_resized / 255.0\n",
        "\n",
        "    return img_normalized, label\n"
      ],
      "metadata": {
        "id": "QpRcfZKb98B6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(keras.losses.Loss):\n",
        "    def __init__(self, gamma=2.0, alpha=0.25, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=5)\n",
        "        epsilon = keras.backend.epsilon()\n",
        "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "        cross_entropy = -y_true_one_hot * tf.math.log(y_pred)\n",
        "        alpha_t = y_true_one_hot * self.alpha + (1 - y_true_one_hot) * (1 - self.alpha)\n",
        "        p_t = y_true_one_hot * y_pred + (1 - y_true_one_hot) * (1 - y_pred)\n",
        "        focal_loss = alpha_t * tf.pow((1. - p_t), self.gamma) * cross_entropy\n",
        "        return tf.reduce_sum(focal_loss, axis=-1)"
      ],
      "metadata": {
        "id": "QPL3WTEN-CqH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_classes=5):\n",
        "    base_model = tf.keras.applications.ResNet50V2(\n",
        "        input_shape=(224, 224, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = keras.Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "St-He02T-GPV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = train_labels_df[\"image_path\"].tolist()\n",
        "labels = train_labels_df[\"level\"].tolist()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
        "\n",
        "train_size = int(0.8 * len(image_paths))\n",
        "train_ds_raw = dataset.take(train_size)\n",
        "val_ds_raw = dataset.skip(train_size)\n",
        "\n",
        "train_dataset = train_ds_raw.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_dataset = val_ds_raw.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "model = build_model()\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=FocalLoss(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=3,  # just a few epochs since sample is tiny\n",
        "    validation_data=val_dataset\n",
        ")\n",
        "\n",
        "print(\"✅ Training complete (sample dataset)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6PrxiXD-JLv",
        "outputId": "5991c04b-3939-4a9c-c387-6b4cefb27707"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Epoch 1/3\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.5000 - loss: 0.6475 - val_accuracy: 1.0000 - val_loss: 9.9348e-04\n",
            "Epoch 2/3\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.5000 - loss: 0.5479 - val_accuracy: 0.0000e+00 - val_loss: 0.8233\n",
            "Epoch 3/3\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.3750 - loss: 0.3975 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
            "✅ Training complete (sample dataset)\n"
          ]
        }
      ]
    }
  ]
}